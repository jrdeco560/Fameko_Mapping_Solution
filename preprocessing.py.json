{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "from subprocess import run, CalledProcessError\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "from multiprocessing import Pool\n",
    "import shutil\n",
    "\n",
    "# commandline argument setup\n",
    "parser = argparse.ArgumentParser(description='Process address data to a single osm file per state')\n",
    "parser.add_argument('state-list', nargs='+', help='lowercase 2 letter state abbreviation')\n",
    "parser.add_argument('--update-oa', action='store_true', help='downloads OA data for entire US')\n",
    "parser.add_argument('--load-oa', action='store_true', help='loads OA data into database, overwriting previous')\n",
    "parser.add_argument('--filter-data', action='store_true', help='delete unwanted data from database')\n",
    "parser.add_argument('--output-osm', action='store_true', help='output data from database to OSM files')\n",
    "parser.add_argument('--update-osm', action='store_true', help='downloads latest state extract, overwrites previous')\n",
    "parser.add_argument('--quality-check', action='store_true', help='sort output file and run basic quality checks')\n",
    "parser.add_argument('--slice', action='store_true', help='splits states into smaller regions if config present')\n",
    "parser.add_argument('--all', action='store_true', help='use all options')\n",
    "args = parser.parse_args()\n",
    "if args.all:\n",
    "    args.update_oa == True\n",
    "    args.update_osm == True\n",
    "    args.load_oa == True\n",
    "    args.output_osm == True\n",
    "    args.quality_check == True\n",
    "    args.filter_data == True\n",
    "state_list = vars(args)['state-list']\n",
    "# state_list = ['mt']\n",
    "\n",
    "\n",
    "def update_oa(url):\n",
    "    '''\n",
    "    downloads US files from OpenAddresses and unzips them, overwriting previous files\n",
    "    '''\n",
    "    filename = Path(url).name\n",
    "    run(['curl', '-o', filename, url])\n",
    "    run(['unzip', '-o', filename])\n",
    "\n",
    "\n",
    "def load_csv(path, state):\n",
    "    '''\n",
    "    accepts path object of file to load and state name as string\n",
    "    loads files into postgres and generates geometry column\n",
    "    '''\n",
    "    name = path.stem\n",
    "    os.system('ogr2ogr PG:dbname=gis {0} -nln {1}_{2} -overwrite -lco OVERWRITE=YES'.format(path, name, state))\n",
    "\n",
    "\n",
    "def pg2osm(path, id_start, state):\n",
    "    '''\n",
    "    input path object of openaddresses file , id to start numbering at, state name as string\n",
    "    output osm format file excluding empty rows\n",
    "    '''\n",
    "    name = path.stem\n",
    "    number_field = 'number'\n",
    "    r = run('psql -d gis -c \"select pg_typeof({0}) from \\\\\"{1}_{2}\\\\\" limit 1;\"'.format(number_field, name, state), shell=True, capture_output=True, encoding='utf8').stdout\n",
    "    if 'character' in r:\n",
    "        try:\n",
    "            os.system('python3 /opt/ogr2osm/ogr2osm.py -f --id={0} -t addr_oa.py -o {3}/{1}_addresses.osm \"PG:dbname=gis user=pat password=password host=localhost\" --sql \"select * from \\\\\"{1}_{3}\\\\\" where {2} is not null and {2}!=\\'\\' and {2}!=\\'0\\'\"'.format(id_start, name, number_field, state))\n",
    "        except Exception:\n",
    "            print('ogr2osm failure')\n",
    "            raise\n",
    "            return id_start\n",
    "        stats = run('osmium fileinfo -ej {1}/{0}_addresses.osm'.format(name, state), shell=True, capture_output=True, encoding='utf8')\n",
    "        # handle files with hashes only\n",
    "        try:\n",
    "            id_end = json.loads(stats.stdout)['data']['minid']['nodes']\n",
    "        except Exception:\n",
    "            print('{0}_{1} is hashes only'.format(name, state))\n",
    "            raise\n",
    "            return id_start\n",
    "    elif 'integer' in r or 'numeric' in r:\n",
    "        try:\n",
    "            os.system('python3 /opt/ogr2osm/ogr2osm.py -f --id={0} -t addr_oa.py -o {3}/{1}_addresses.osm \"PG:dbname=gis user=pat password=password host=localhost\" --sql \"select * from \\\\\"{1}_{3}\\\\\" where {2} is not null and {2}!=0\"'.format(id_start, name, number_field, state))\n",
    "        except Exception:\n",
    "            print('ogr2osm failure')\n",
    "            raise\n",
    "            return id_start\n",
    "        stats = run('osmium fileinfo -ej {1}/{0}_addresses.osm'.format(name, state), shell=True, capture_output=True, encoding='utf8')\n",
    "        try:\n",
    "            id_end = json.loads(stats.stdout)['data']['minid']['nodes']\n",
    "        except Exception:\n",
    "            print('{0}_{1} is hashes only'.format(name, state))\n",
    "            raise\n",
    "            return id_start\n",
    "    # handle empty file\n",
    "    else:\n",
    "        print('{0}_{1} is empty'.format(name, state))\n",
    "        raise\n",
    "        return id_start\n",
    "    return id_end\n",
    "\n",
    "\n",
    "def create_master_list(state, master_list, oa_root):\n",
    "    '''\n",
    "    input: state as 2 letter abbrev., dict for sources to go into, root directory for oa\n",
    "    output: dict with 2 letter state abbrev. as key and list of sources as value\n",
    "    goes through each state folder and creates list of vrt files\n",
    "    '''\n",
    "    oa_state_folder = oa_root.joinpath(Path(state))\n",
    "    file_list = [] \n",
    "    for filename in oa_state_folder.iterdir():\n",
    "        # - is not allowed in postgres\n",
    "        if '-' in filename.name and filename.suffix == '.vrt':\n",
    "            filename_new = filename.parent.joinpath(Path(filename.name.replace('-', '_')))\n",
    "            os.rename(filename, filename_new)\n",
    "            file_list.append(filename_new)\n",
    "        elif filename.suffix == '.vrt':\n",
    "            file_list.append(filename)\n",
    "        \n",
    "    master_list[state] = file_list\n",
    "    print(state + ' ' + 'Master List Created')\n",
    "    return master_list\n",
    "\n",
    "\n",
    "def load_oa(state, master_list):\n",
    "    file_list = master_list[state]\n",
    "    for j in file_list:\n",
    "        load_csv(j, state)\n",
    "    print(state + ' ' + 'Load Finished')\n",
    "    return\n",
    "\n",
    "\n",
    "def output_osm(state, master_list, id, root):\n",
    "    file_list = master_list.get(state)\n",
    "    removal_list = []\n",
    "    # create folder for osm files\n",
    "    state_folder = root.joinpath(Path(state))\n",
    "    try:\n",
    "        os.mkdir(state_folder)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    for j in file_list:\n",
    "        # catch error and log file for removal from master list\n",
    "        # sql join then output once quicker?\n",
    "        try:\n",
    "            print('writing osm file for ' + j.as_posix())\n",
    "            id = pg2osm(j, id, state)\n",
    "        except Exception:\n",
    "            removal_list.append(j)\n",
    "    # remove file from file list so merge will work\n",
    "    for i in removal_list:\n",
    "        file_list.remove(i)\n",
    "    master_list[state] = file_list \n",
    "    return master_list\n",
    "\n",
    "\n",
    "# update osm data\n",
    "def update_osm(state, state_expander):\n",
    "    state_expanded = state_expander.get(state)\n",
    "    # format for url\n",
    "    state_expanded = state_expanded.replace(' ', '-')\n",
    "    run('curl --output {1}/{0}-latest.osm.pbf https://download.geofabrik.de/north-america/us/{0}-latest.osm.pbf'.format(state_expanded, state), shell=True, capture_output=True, encoding='utf8')\n",
    "    return\n",
    "\n",
    "\n",
    "def merge(state, master_list, state_expander):\n",
    "    '''\n",
    "    input: state as 2 letter abbrev., dict of sources to be merged, dict to expand state abbrev. to full name\n",
    "    output: merged state pbf in state folder\n",
    "    '''\n",
    "    list_files_string = []\n",
    "    file_list = master_list.get(state)\n",
    "    for i in file_list:\n",
    "        list_files_string.append(i.as_posix())\n",
    "    file_list_string = ' '.join(list_files_string).replace('us/', '').replace('.vrt', '_addresses.osm')\n",
    "    state_expanded = state_expander.get(state)\n",
    "    state_expanded = state_expanded.replace(' ', '-')\n",
    "    try:\n",
    "        run('osmium merge -Of pbf {0} {1}/{2}-latest.osm.pbf -o {1}/Us_{2}_northamerica_alpha.osm.pbf'.format(file_list_string, state, state_expanded), shell=True, capture_output=True, check=True, encoding='utf8')\n",
    "    except Exception as e:\n",
    "        print(e.stderr)\n",
    "        print(state + ' ' + 'Merge Failed')\n",
    "        return\n",
    "    print(state + ' ' + 'Merge Finished')\n",
    "    return\n",
    "\n",
    "def prep_for_qa(state, state_expander, master_list):\n",
    "    '''\n",
    "    input: state abbrev, state_expander dict, master_list\n",
    "    output: stats for last source ran, state extract and final file\n",
    "    '''\n",
    "    state_expanded = state_expander.get(state)\n",
    "    state_expanded = state_expanded.replace(' ', '-')\n",
    "    # osmium sort runs everything in memory, may want to use osmosis instead\n",
    "    run('osmium sort --overwrite {0}/Us_{1}_northamerica_alpha.osm.pbf -o {0}/Us_{1}_northamerica_alpha.osm.pbf'.format(state, state_expanded), shell=True, encoding='utf8')\n",
    "    # find last source ran\n",
    "    file_list = master_list.get(state)\n",
    "    last_source = Path(Path(file_list[-1]).as_posix().replace('us/', '').replace('.vrt', '_addresses.osm'))\n",
    "    print(last_source.as_posix())\n",
    "    # get data for last source ran\n",
    "    stats = run('osmium fileinfo -ej {0}'.format(last_source), shell=True, capture_output=True, encoding='utf8')\n",
    "    # get data for OSM extract\n",
    "    stats_state = run('osmium fileinfo -ej {0}/{1}-latest.osm.pbf'.format(state, state_expanded), shell=True, capture_output=True, encoding='utf8')\n",
    "    # get data for completed state file\n",
    "    stats_final = run('osmium fileinfo -ej {0}/Us_{1}_northamerica_alpha.osm.pbf'.format(state, state_expanded), shell=True, capture_output=True, encoding='utf8')\n",
    "    return stats, stats_state, stats_final\n",
    "\n",
    "def quality_check(stats, stats_state, stats_final):\n",
    "    '''\n",
    "    input: stats for last source ran, state extract and final file\n",
    "    output: boolean that is True for no issues or False for issues\n",
    "    '''\n",
    "    ready_to_move = True\n",
    "    # file is not empty\n",
    "    # Check if items have unique ids\n",
    "    if json.loads(stats_final.stdout)['data']['multiple_versions'] == 'True':\n",
    "        print('ERROR: Multiple items with same id')\n",
    "        ready_to_move = False\n",
    "    # Check if added data overlaps with OSM ids\n",
    "    if json.loads(stats_state.stdout)['data']['maxid']['nodes'] >= json.loads(stats.stdout)['data']['minid']['nodes']:\n",
    "        print('ERROR: Added data overlaps with OSM data')\n",
    "        ready_to_move = False\n",
    "    return ready_to_move\n",
    "\n",
    "def move(state, state_expander, ready_to_move, pbf_output, sliced_state=None):\n",
    "    '''\n",
    "    input: state abbrev, state_expander dict, ready_to_move boolean, pbf_output location\n",
    "    action: moves final file to pbf_output location\n",
    "    output: nothing\n",
    "    '''\n",
    "    state_expanded = state_expander.get(state)\n",
    "    state_expanded = state_expanded.replace(' ', '-')\n",
    "    # move sliced files\n",
    "    if sliced_state is not None and ready_to_move:\n",
    "        for slice_config in sliced_state:\n",
    "            slice_name = slice_config[0]\n",
    "            run(['mv','{0}/Us_{1}_{2}_northamerica_alpha.osm.pbf'.format(state, state_expanded, slice_name), pbf_output])\n",
    "    # move all other files\n",
    "    elif ready_to_move:\n",
    "        run(['mv','{0}/Us_{1}_northamerica_alpha.osm.pbf'.format(state, state_expanded), pbf_output])\n",
    "\n",
    "def filter_data(state, master_list):\n",
    "    '''\n",
    "    input: state, master_list\n",
    "    action: delete records with bad data\n",
    "    output: none\n",
    "    '''\n",
    "    file_list = master_list.get(state)\n",
    "    number_field = 'number'\n",
    "    for j in file_list:\n",
    "        name = j.stem\n",
    "        # delete records with -- in nubmer field eg rancho cucamonga\n",
    "        r = run('psql -d gis -c \"DELETE from \\\\\"{1}_{2}\\\\\" where {0}=\"--\";\"'.format(number_field, name, state), shell=True, capture_output=True, encoding='utf8')\n",
    "        print(r.stdout)\n",
    "        # print('Removed -- from {0}_{1}'.format(name, state))\n",
    "        # take standard shell and run through shlex.split to use run properly\n",
    "        # delete record with illegal unicode chars in number field\n",
    "        r = run( ['psql', '-d', 'gis', '-c', \"delete from \\\"{1}_{2}\\\" where {0} ~ '[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1F\\uFFFE\\uFFFF]';\".format(number_field, name, state)], capture_output=True, encoding='utf8')\n",
    "        print(r.stdout)\n",
    "        # print('Removed illegal unicode from {0}_{1}'.format(name, state))\n",
    "\n",
    "def slice(state, state_expander):\n",
    "    '''\n",
    "    input: state, state_expander, (name of slice and bounding box coordinates in lon,lat,lon,lat)\n",
    "    file requirement: file must be sorted for osmium extract to work; running --quality-check handles this\n",
    "    action: slices merged files according to config\n",
    "    output: config of sliced state\n",
    "    # states above ~200MB can crash osmand map generator, slice into smaller regions before processing\n",
    "    '''\n",
    "    config = {}\n",
    "    config['co'] = [['north', '-109.11,39.13,-102.05,41.00'], ['south', '-109.11,39.13,-102.04,36.99']]\n",
    "    config['fl'] = [['north', '-79.75,27.079,-87.759,31.171'], ['south', '79.508,24.237,-82.579,27.079']]\n",
    "    config['tx'] = [['southeast','-96.680,24.847,-93.028,30.996'],['northeast','-96.680,24.847,-93.028,30.996'],['northwest','-96.028,30.996,-108.391,36.792'],['southwest','-96.028,30.996,-107.556,25.165']]\n",
    "    config['ca'] = [['north','-119.997,41.998,-125.365,38.964'],['northcentral','-125.365,38.964,-114.049,37.029'],['central','-114.049,37.029,-123.118,34.547'],['southcentral','-123.118,34.547,-113.994,33.312'],['south','-113.994,33.312,-119.96,31.85']]\n",
    "    state_expanded = state_expander.get(state)\n",
    "    if state in config.keys():\n",
    "        for slice_config in config[state]:\n",
    "            # better as dict?\n",
    "            slice_name = slice_config[0]\n",
    "            bounding_box = slice_config[1]\n",
    "            try:\n",
    "                run('osmium extract -O -b {3} -o {0}/Us_{1}_{2}_northamerica_alpha.osm.pbf {0}/Us_{1}_northamerica_alpha.osm.pbf'.format(state, state_expanded, slice_name, bounding_box), shell=True, capture_output=True, check=True,encoding='utf8')\n",
    "            except Exception as e:\n",
    "                print(e.stderr)\n",
    "        sliced_state = config[state]\n",
    "        return sliced_state\n",
    "\n",
    "# run osmand map creator\n",
    "# batch.xml needs to be setup\n",
    "# move files into osm directory defined in batch.xml\n",
    "# java -Djava.util.logging.config.file=logging.properties -Xms64M -Xmx6300M -cp \"./OsmAndMapCreator.jar:lib/OsmAnd-core.jar:./lib/*.jar\" net.osmand.util.IndexBatchCreator batch.xml\n",
    "\n",
    "\n",
    "def run_all(state):\n",
    "    state_expander = {'al':'alabama', 'ak':'alaska','ar':'arkansas','az':'arizona','ca':'california','co':'colorado','ct':'connecticut','de':'delaware','fl':'florida','ga':'georgia','hi':'hawaii','ia':'iowa','id':'idaho','il':'illinois','in':'indiana', 'ks':'kansas','ky':'kentucky', 'la':'louisiana','me':'maine','md':'maryland','ma':'massachusetts','mi':'michigan', 'mn':'minnesota','ms':'mississippi','mo':'missouri', 'mt':'montana', 'nd':'north dakota', 'ne':'nebraska','nh':'new hampshire','nj':'new jersey','nm':'new mexico','ny':'new york','nc':'north carolina', 'nv':'nevada','oh':'ohio','ok':'oklahoma', 'or':'oregon','pa':'pennsylvania','ri':'rhode island','sc':'south carolina','sd':'south dakota','tn':'tennessee','tx':'texas','ut':'utah','vt':'vermont','va':'virginia','wa':'washington','wv':'west virginia','wi':'wisconsin','wy':'wyoming'}\n",
    "    oa_root = Path('/home/pat/projects/osmand_map_creation/osmand_osm/osm/us/')\n",
    "    # root assumed to be child folder of pbf_output\n",
    "    root = Path('/home/pat/projects/osmand_map_creation/osmand_osm/osm/')\n",
    "    pbf_output = root.parent\n",
    "    master_list = {}\n",
    "    # id to count down from for each state\n",
    "    id = 2**33\n",
    "    master_list = create_master_list(state, master_list, oa_root)\n",
    "    if args.load_oa == True:\n",
    "        load_oa(state, master_list)\n",
    "    if args.filter_data:\n",
    "        filter_data(state, master_list)\n",
    "    if args.output_osm:\n",
    "        master_list = output_osm(state, master_list, id, root)\n",
    "    if args.update_osm == True:\n",
    "        update_osm(state, state_expander)\n",
    "    if args.output_osm:\n",
    "        merge(state, master_list, state_expander)\n",
    "    # allows running without quality check\n",
    "    ready_to_move = True\n",
    "    if args.quality_check:\n",
    "        stats, stats_state, stats_final = prep_for_qa(state, state_expander, master_list)\n",
    "        ready_to_move = quality_check(stats, stats_state, stats_final)\n",
    "    if args.slice:\n",
    "        sliced_state = slice(state, state_expander)\n",
    "    if args.output_osm and args.slice:\n",
    "        move(state, state_expander, ready_to_move, pbf_output, sliced_state) \n",
    "    elif args.output_osm:\n",
    "        move(state, state_expander, ready_to_move, pbf_output) \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # memory can be limit with large files, consider switching pool to 1 or doing 1 state at a time with cron job\n",
    "    with Pool(2) as p:\n",
    "        if args.update_oa == True:\n",
    "            oa_urls = ['https://data.openaddresses.io/openaddr-collected-us_midwest.zip', 'https://data.openaddresses.io/openaddr-collected-us_south.zip', 'https://data.openaddresses.io/openaddr-collected-us_west.zip', 'https://data.openaddresses.io/openaddr-collected-us_northeast.zip']\n",
    "            p.map(update_oa, oa_urls)\n",
    "        p.map(run_all, state_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
